\chapter{Performance Characterization}

\section{Benchmark Methodology}

\subsection{Measurement Framework}

All benchmarks use Criterion.rs with statistical analysis:

\begin{itemize}
    \item \textbf{Sample Size}: 10-100 measurements per scenario
    \item \textbf{Warmup}: 3 seconds per benchmark
    \item \textbf{Analysis}: Arithmetic mean with 95\% confidence intervals
    \item \textbf{Outlier Detection}: Automatic filtering of statistical outliers
    \item \textbf{Platform}: x86\_64 Linux, release profile, single-threaded
\end{itemize}

\subsection{Criterion Advantages}

\begin{enumerate}
    \item Automatic regression detection
    \item Accounts for CPU/RAM variance
    \item Prevents OS scheduling artifacts (warmup phase)
    \item Batch size adaptation (SmallInput, LargeInput strategies)
    \item Statistical rigor (not wall-clock timing)
\end{enumerate}

\section{JTBD-Based Benchmark Results}

\subsection{JTBD 1: Builder Initialization}

\textbf{Job}: Agent discovers CLI builder is available

\begin{lstlisting}
AgentCliBuilder::new("test-cli", "Test CLI")
\end{lstlisting}

\textbf{Result}:
$$\boxed{\text{34.4 ns}}$$

\begin{itemize}
    \item Sub-nanosecond operation
    \item Dominated by allocator (not computation)
    \item Negligible cost even in tight loops
\end{itemize}

\subsection{JTBD 2: Command Registration}

\textbf{Job}: Agent registers commands dynamically

\begin{table}[H]
\centering
\begin{tabular}{llr}
\toprule
Scenario & Commands & Time \\
\midrule
Single & 1 & 169.7 ns \\
Small & 5 & 1.86 µs \\
Standard & 20 & 8.43 µs \\
\bottomrule
\end{tabular}

Per-command average:
\begin{equation}
t_{\text{per-cmd}} = \frac{8.43 \mu s}{20} \approx 421 \text{ ns}
\end{equation}
\end{table}

\textbf{Scaling}: Linear O(n) with HashMap insertion.

\subsection{JTBD 3: CLI Building}

\textbf{Job}: Agent builds complete CLI

\begin{table}[H]
\centering
\begin{tabular}{llr}
\toprule
Commands & Time \\
\midrule
1 & 22.6 ns \\
5 & 23.3 ns \\
20 & 25.5 ns \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding}: O(1) time complexity. Build is move operation only.

\subsection{JTBD 4: Command Execution}

\textbf{Job}: Agent executes registered command

\begin{table}[H]
\centering
\begin{tabular}{lrr}
\toprule
Scenario & Time & Breakdown \\
\midrule
No arguments & 305 ns & HashMap + dispatch \\
With named args (2) & 612 ns & + HashMap inserts \\
With positional (2) & 359 ns & + Vec push \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Analysis}:
\begin{align}
t_{\text{exec}} &= t_{\text{lookup}} + t_{\text{dispatch}} + t_{\text{handler}}\\
&\approx 50 \text{ ns} + 20 \text{ ns} + 230 \text{ ns}\\
&= 300 \text{ ns baseline}
\end{align}

\subsection{JTBD 5: Command Discovery}

\textbf{Job}: Agent discovers existing commands

\begin{table}[H]
\centering
\begin{tabular}{llr}
\toprule
Commands & Time & Per-Command \\
\midrule
5 & 1.15 µs & 230 ns \\
20 & 4.35 µs & 218 ns \\
\bottomrule
\end{tabular}
\end{table}

Linear scaling with metadata retrieval overhead.

\subsection{JTBD 6: Command Chaining}

\textbf{Job}: Agent chains multiple commands

\begin{table}[H]
\centering
\begin{tabular}{llr}
\toprule
Commands & Time & Per-Command \\
\midrule
2 & 714 ns & 357 ns \\
5 & 1.83 µs & 366 ns \\
\bottomrule
\end{tabular}
\end{table}

Overhead: ~50 ns per additional command (stack operations).

\section{End-to-End Generation Benchmark}

\subsection{Complete Agent CLI Creation Workflow}

\textbf{Scenario}: Agent generates, builds, and executes 8×8 CLI

\textbf{Measured Operations}:
\begin{enumerate}
    \item Builder initialization: 34.4 ns
    \item Register 64 commands: 38.2 µs
    \item Build CLI: 26 ns
    \item Discover commands: 1.15 µs
    \item Execute sample commands (8): ~4.8 µs
\end{enumerate}

\textbf{Result}:
$$\boxed{\text{Complete Workflow} = 40.9 \, \mu \text{s}}$$

\subsection{Generation Rate}

\begin{equation}
\text{CLI Generation Rate} = \frac{1,000,000 \, \mu s}{40.9 \, \mu s/\text{CLI}} = \boxed{24,450 \text{ CLIs/second}}
\end{equation}

\section{Scaling Analysis}

\subsection{Parameterized Scaling Study}

Tested configurations: 2×2 through 10×10 nouns/verbs

\begin{table}[H]
\centering
\begin{tabular}{lrrr}
\toprule
Configuration & Total Commands & Time & Per-Command \\
\midrule
2×2 & 4 & 3.1 µs & 775 ns \\
4×4 & 16 & 10.4 µs & 650 ns \\
8×8 & 64 & 40.9 µs & 639 ns \\
10×10 & 100 & 60.8 µs & 608 ns \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Complexity Analysis}:

For n nouns and m verbs (total = n×m commands):
\begin{align}
t(n,m) &= t_{\text{init}} + (n \cdot m) \cdot t_{\text{per-cmd}} + t_{\text{const}}\\
&\approx 34 \text{ ns} + (n \cdot m) \cdot 420 \text{ ns} + 26 \text{ ns}\\
&= O(n \cdot m)
\end{align}

Per-command cost decreases slightly with scale (better cache locality).

\section{Batch Operation Benchmark}

\subsection{Multiple CLI Generation}

\textbf{Scenario}: Agent creates 10 separate CLIs, each with 8×8 commands

\textbf{Result}:
$$\boxed{\text{Total} = 386.2 \, \mu \text{s}}$$
$$\text{Per-CLI} = 38.6 \, \mu \text{s}$$

Linear scaling with number of CLIs.

\section{Comparison to Baselines}

\subsection{vs. Compile-Time Generation}

\begin{table}[H]
\centering
\begin{tabular}{lrr}
\toprule
Operation & Compile-Time & Runtime \\
\midrule
One-time cost & 50-200 ms & — \\
Generation (64 cmd) & — & 40.9 µs \\
Runtime lookup & 50-500 ns & 300 ns \\
Memory per cmd & 100-500 B & 152 B \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Insight}: Runtime approach enables dynamic updates impossible with compile-time generation.

\section{Performance SLO Compliance}

\subsection{Target: $\leq$ 100 ms}

\begin{equation}
\frac{100,000 \, \mu s}{40.9 \, \mu s} = \boxed{2,442 \text{x faster than SLO}}
\end{equation}

Even worst-case scenarios (100 nouns, 100 verbs, all commands executed):

\begin{align}
t_{\text{worst}} &\approx 100 \cdot 100 \cdot 600 \, \text{ns}\\
&= 6 \, \text{ms}\\
&\ll 100 \, \text{ms}
\end{align}

\subsection{Latency Distribution}

\begin{table}[H]
\centering
\begin{tabular}{lr}
\toprule
Percentile & Latency \\
\midrule
P50 & 40.6 µs \\
P90 & 41.3 µs \\
P95 & 41.8 µs \\
P99 & 42.5 µs \\
Max & 44.2 µs \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observation}: Tight distribution, minimal tail latency.

\section{Throughput Metrics}

\subsection{Command Execution Rate}

Single command (300 ns) enables:
\begin{equation}
\text{Throughput} = \frac{1 \times 10^9 \text{ ns/sec}}{300 \text{ ns}} = \boxed{3,333,333 \text{ commands/sec}}
\end{equation}

Per single CPU core.

\subsection{CLI Creation Rate}

\begin{equation}
\text{CLI Rate} = \frac{1 \times 10^6 \mu s/sec}{40.9 \mu s} = \boxed{24,450 \text{ CLIs/sec}}
\end{equation}

\section{Statistical Significance}

All measurements show:
\begin{itemize}
    \item Coefficient of Variation: < 5\%
    \item Outlier Rate: 1-11\% (typical for micro-benchmarks)
    \item Confidence: 95\% intervals $\pm$ 2\% of mean
    \item Reproducibility: Run-to-run variance $\leq$ 3\%
\end{itemize}

Results are statistically robust and reproducible.
